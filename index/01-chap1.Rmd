# Pre-processing of Microbiome Sequencing Data

Microbiome data can be procured from a multitude of sample types, including skin, the vagina, and the gut. Taken immediately from a wet-lab experiment, microbiome data starts off simply as a collection of FASTQ reads, each representing different bacterial sequences identified within the sample. 

Identification and clustering of these reads is required to produce a representation of microbiome data that can be effectively used for data analysis.The classic format of these processed data is known as the Operational Taxonomic Unit (OTU) table. These tables group DNA sequences into "molecular operational taxonomic units, clusters of sequencing reads that differ by less than a fixed dissimilarity threshold" (Callahan 2017). Each row in the table represents a sample, and each column represents a different OTU. In the past couple of years, new methods have allowed researchers to work with amplicon sequence variants (ASVs) instead of OTUs. ASV groupings can be "resolved exactly, down to the level of single-nucleotide differences over the sequenced gene region," allowing for improved resolution of processed data (Callahan 2017). The DADA2 pipeline in R can be used to process microbiome sequence data and create an ASV table, yielding "more real variants and output[ting] fewer spurious sequences than other methods" (Callahan 2016).

As an exploration of the use of the DADA2 pipeline for the processing of microbiome sequencing data, we used the European Nucleotide Archive (Harrison 2018) to download raw read data from Catherine Lozupone's 2013 study on gut-linked diseases prevalent in HIV (Lozupone 2013). With these data, we applied Benjamin Callahan's 2016 paper, "Bioconductor Workflow for Microbiome Analysis: from raw reads to community analyses," to manipulate the Lozupone sequencing data. With this pipeline, we visualized the fastq quality scores of our read files (Figure \@ref(fig:figure1)) to trim our input reads at ideal positions. We also filtered reads through the enforcement of a maximum of 2 expected errors per read. 

```{r figure1, fig.cap="Fastq quality scores for a sample read file", out.width = "700px",echo=FALSE}
include_graphics(path = "figure/figure1.png")
```

Following the filtration of input reads, we used DADA2 to infer ASVs. Demultiplexed, dereplicated fastq files were selected for each sample. A sufficiently large subset of our data was taken, and then the DADA2 iterative sequence inference algorithm was run to estimate error rates. We inspected the fit between observed error rates and fitted error rates to verify that our estimations were reasonable (Figure \@ref(fig:figure2))

```{r figure2, fig.cap="Comparison of observed and fitted error rates from the DADA2 iterative sequence inference algorithm", out.width = "700px",echo=FALSE}
include_graphics(path = "figure/figure2.png")
```

Using inference on pooled sequencing reads from all samples, DADA2 then removed nearly all substition and indel errors from our data. Finally, a sequence table was constructed from our sequences.

Just as processing of sequencing data was completed for the Lozupone dataset, Alex Sibley, a bioinformatician working with the Sung lab in the Duke School of Medicine, created an ASV table using the Memorial Sloan Kettering leukemia data. Given these data, we continued through the Callahan workflow to further filter and process our data.
